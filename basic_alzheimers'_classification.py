# -*- coding: utf-8 -*-
"""Basic_Alzheimers'_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vfYEcIkBoVjg_-nUJ01QrjluslT0t6nT
"""

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/Dataset'

import os

subfolders = os.listdir(data_dir)

for file in subfolders:
    print(file)
print(f"Number of subfolders: {len(subfolders)}")

all_files = os.walk(data_dir)

for root, dirs, files in all_files:
    print(f"root: {root}")
    print(f"directories: {dirs}")
    print(f"files: {files}")

import os

# Dictionary to store the count of files in each class
class_counts = {}

# Iterate over all files
for root, dirs, files in os.walk(data_dir):
    for file in files:
        if file.endswith('.jpg'):
            class_name = os.path.basename(root)
            if class_name not in class_counts:
                class_counts[class_name] = 0
            class_counts[class_name] += 1

# Print the count of files in each class
for class_name, count in class_counts.items():
    print(f"Class: {class_name}, Number of Files: {count}")

image_files = []

for root, directories, files in os.walk(data_dir):
    for file in files:
        if file.endswith('.jpg'):
            image_files.append(os.path.join(root, file))

print(f"The number of image files: {len(image_files)}")





#import cv2
#import numpy as np
#X = []
#y = []

f#or file in image_files:
  #  img = cv2.imread(file)
   # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    #img = img.astype('float32') / 255.0
    #X.append(img)
    #label = file.split('/')[-2]
    #y.append(label)

#X = np.array(X)
#y = np.array(y)

import cv2
import numpy as np
X = []
y = []

for file in image_files:
    img = cv2.imread(file)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = img.astype('float32') / 255.0
    X.append(img)
    label = file.split('/')[-2]
    y.append(label)

X = np.array(X)
y = np.array(y)

X[0]

import random
classes = np.unique(y)
selected_images = {}
for label in classes:
    class_images = X[y == label]
    selected = random.sample(list(class_images), 4)
    selected_images[label] = selected

import matplotlib.pyplot as plt
fig, axs = plt.subplots(1, 4, figsize=(10,10))
for i in range(4):
   axs[i].imshow(selected_images[classes[i]][0])
   axs[i].set_title(classes[i])
   axs[i].axis("off")

plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)

print('Training set shape:', X_train.shape, y_train.shape)
print('Validation set shape:', X_valid.shape, y_valid.shape)
print('Testing set shape:', X_test.shape, y_test.shape)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from tensorflow.keras.callbacks import ModelCheckpoint
from imblearn.over_sampling import ADASYN
import cv2

# Function to resize images
def resize_images(images, target_size):
    resized_images = []
    for img in images:
        resized_img = cv2.resize(img, target_size)
        resized_images.append(resized_img)
    return np.array(resized_images)

# Resize images to a smaller resolution
target_size = (128, 128)
X_resized = resize_images(X, target_size)

# Split the data into train, validation, and test sets
X_train_val, X_test, y_train_val, y_test = train_test_split(X_resized, y, test_size=0.2, random_state=123)
X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=123)  # 0.25 x 0.8 = 0.2

# Apply ADASYN to the training data
adasyn = ADASYN(random_state=42)

# Encode the class labels to numeric values
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_valid_encoded = label_encoder.transform(y_valid)

# Reshape images for compatibility with Conv2D layers
X_train_reshaped = X_train.reshape(-1, target_size[0], target_size[1], 1)  # Add 1 channel for grayscale
X_valid_reshaped = X_valid.reshape(-1, target_size[0], target_size[1], 1)

# Reshape images to 2D for ADASYN
X_train_flat = X_train_reshaped.reshape(X_train_reshaped.shape[0], -1)
X_valid_flat = X_valid_reshaped.reshape(X_valid_reshaped.shape[0], -1)

# Apply ADASYN to the training data
X_train_resampled_flat, y_train_resampled = adasyn.fit_resample(X_train_flat, y_train_encoded)
X_valid_resampled_flat, y_valid_resampled = adasyn.fit_resample(X_valid_flat, y_valid_encoded)

# Reshape images back to 4D
X_train_resampled = X_train_resampled_flat.reshape(-1, target_size[0], target_size[1], 1)
X_valid_resampled = X_valid_resampled_flat.reshape(-1, target_size[0], target_size[1], 1)

# Convert labels to one-hot encoding
num_classes = len(np.unique(y_train_encoded))
y_train_one_hot = to_categorical(y_train_resampled, num_classes=num_classes)
y_valid_one_hot = to_categorical(y_valid_resampled, num_classes=num_classes)
y_test_one_hot = to_categorical(label_encoder.transform(y_test), num_classes=num_classes)

# Model configuration
model = Sequential()
model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer="he_normal", input_shape=(target_size[0], target_size[1], 1)))  # Input shape changes to (64, 64, 1)
model.add(MaxPooling2D())
model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer="he_normal"))
model.add(MaxPooling2D())
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(units=128, activation='relu'))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Model checkpoint
checkpoint = ModelCheckpoint(filepath='model_kaggle_alzheimer.h5', save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)

# Training the model

import time


start_time = time.time()

history = model.fit(X_train_resampled, y_train_one_hot, validation_data=(X_valid_resampled, y_valid_one_hot), epochs=50, batch_size=32, callbacks=[checkpoint])

end_time = time.time()


process_time = end_time - start_time
print(f"Training process time: {process_time} seconds")

loss, accuracy = model.evaluate(X_valid_resampled, y_valid_one_hot)

print(f"Validation loss: {round(loss, 2)}")
print(f"Validation accuracy: {round(accuracy, 2)}")

import numpy as np
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Generate predictions on the validation set
y_pred = model.predict(X_valid_resampled)
# Decode the predictions from one-hot encoding to numeric labels
y_pred_decoded = np.argmax(y_pred, axis=1)
# Decode the true labels from one-hot encoding to numeric labels
y_valid_decoded = np.argmax(y_valid_one_hot, axis=1)

# Calculate the confusion matrix
conf_matrix = confusion_matrix(y_valid_decoded, y_pred_decoded)

# Plot the confusion matrix
plt.figure(figsize=(6, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], c='b', label='train_accuracy')
plt.plot(history.history['val_accuracy'], c='r', label='validation_accuracy')
plt.title('Accuracy of the CNN model')
plt.legend()
plt.show()

plt.plot(history.history['loss'], c='g', label='train_loss')
plt.plot(history.history['val_loss'], c='y', label='validation_loss')
plt.title('Loss of the CNN model')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score, classification_report

# Predict classes for the validation set
y_pred = model.predict(X_valid_resampled)

# Convert predicted probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert true labels to class labels
y_true = np.argmax(y_valid_one_hot, axis=1)

# Calculate accuracy score
acc = accuracy_score(y_true, y_pred_classes)

print(f"Accuracy score of the model: {round(acc, 2)}")

# Generate classification report
class_names = label_encoder.classes_
class_report = classification_report(y_true, y_pred_classes, target_names=class_names)
print(class_report)

import matplotlib.pyplot as plt
from keras.models import Model

# Load the sample image
sample_image = X_train_resampled[0].reshape(1, target_size[0], target_size[1], 1)

# Create a model that outputs the activations of each layer
layer_outputs = [layer.output for layer in model.layers]
activation_model = Model(inputs=model.input, outputs=layer_outputs)

# Get the output of each layer for the sample image
layer_activations = activation_model.predict(sample_image)

# Visualize the output of each layer
for i, layer_activation in enumerate(layer_activations):
    print("Visualizing Output of Layer {}:".format(i))

    if len(layer_activation.shape) == 4:
        # For Conv2D layers, plot the feature maps
        num_filters = layer_activation.shape[-1]
        fig, axs = plt.subplots(1, num_filters, figsize=(15, 15))
        for j in range(num_filters):
            axs[j].imshow(layer_activation[0, :, :, j], cmap='viridis')
            axs[j].axis('off')
        plt.show()
    elif len(layer_activation.shape) == 2:
        # For Dense layers, print the values
        print(layer_activation)
        print()

from collections import Counter


original_class_counts = Counter(y_train_encoded)


resampled_class_counts = Counter(y_train_resampled)


increase_in_size = {class_label: resampled_class_counts[class_label] - original_class_counts[class_label] for class_label in original_class_counts}


for class_label, increase in increase_in_size.items():
    print(f"Class '{label_encoder.classes_[class_label]}' increased by {increase} samples.")



import numpy as np
import cv2
from keras.models import load_model
from sklearn.preprocessing import LabelEncoder


model = load_model('model_kaggle_alzheimer.h5')
def preprocess_input_image(image_path, target_size=(128, 128)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    resized_img = cv2.resize(img, target_size)
    return resized_img.reshape(1, target_size[0], target_size[1], 1)
def predict_dementia_type(image_path, model):
    preprocessed_image = preprocess_input_image(image_path)
    prediction = model.predict(preprocessed_image)
    predicted_class_index = np.argmax(prediction)
    return predicted_class_index


image_path = '/content/verymild_17.jpg'
predicted_class_index = predict_dementia_type(image_path, model)

label_encoder = LabelEncoder()
label_encoder.fit(y_train)
predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]

print("Predicted dementia type:", predicted_class_label)

import streamlit as st
import numpy as np
from PIL import Image
import cv2
from keras.models import load_model
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input

# Load the model
model = load_model('model_kaggle_alzheimer.h5')

# Function to resize the image
def resize_image(img, target_size):
    img = cv2.resize(img, target_size)
    return img

# Function to preprocess the image
def preprocess_image(img):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to grayscale
    img = cv2.equalizeHist(img)  # Apply histogram equalization for better contrast
    img = img / 255.0  # Normalize pixel values to [0, 1]
    return img

# Function to predict class label
def predict_image_class(img, model):
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    img = np.expand_dims(img, axis=-1)  # Add channel dimension
    prediction = model.predict(img)
    return prediction

# Streamlit app
st.title('Alzheimer Image Classifier')

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Read image file
    img = Image.open(uploaded_file)
    st.image(img, caption='Uploaded Image', use_column_width=True)

    # Preprocess and resize the image
    img = np.array(img)
    img = resize_image(img, (128, 128))
    img = preprocess_image(img)

    # Make prediction
    prediction = predict_image_class(img, model)
    class_idx = np.argmax(prediction)
    confidence = prediction[0][class_idx] * 100

    # Display prediction
    classes = ['Class 0', 'Class 1', 'Class 2', 'Class 3']  # Define your class labels
    st.write(f'Predicted Class: {classes[class_idx]}')
    st.write(f'Confidence: {confidence:.2f}%')

